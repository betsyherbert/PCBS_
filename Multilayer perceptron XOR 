#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Dec 16 12:58:29 2019

@author: pc
"""

import numpy as np
import random

# Define activation function 

def sigmoid(x):
    return 1/(1+np.exp(-x))

def sigmoid_der(x):
    return x*(1-x)

# Create neural network 
    
class NN:
    def __init__(self, inputs):
        random.seed(1)
        self.inputs = inputs
        self.l = len(self.inputs)                                                                                                                           
        self.li = len(self.inputs[0])
        
        self.wi = np.random.random((self.li, self.l))
        self.wh = np.random.random((self.l, 1))
    
    #Forward pass
    def forward(self, inp): 
        s1 = sigmoid(np.dot(inp, self.wi))
        s2 = sigmoid(np.dot(s1, self.wh))
        return s2
    
    # Backward pass 
    def train(self, inputs, outputs, iterations):
        for i in range(iterations):
            l0 = inputs
            l1 = sigmoid(np.dot(l0, self.wi))
            l2 = sigmoid(np.dot(l1, self.wh))
            
            l2_err = outputs - l2
            l2_delta = np.multiply(l2_err, sigmoid_der(l2))
            
            l1_err = np.dot(l2_delta, self.wh.T)
            l1_delta = np.multiply(l1_err, sigmoid_der(l1))
            
            self.wh += np.dot(l1.T, l2_delta)
            self.wi += np.dot(l0.T, l1_delta)
            
# Run perceptron 
            
inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
outputs = np.array([[0], [1], [1], [0]])

n = NN(inputs)
print("Before training:")
print(n.forward(inputs))
n.train(inputs, outputs, 10000)
print("After training:")
print(n.forward(inputs))
