#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sun Dec 15 17:10:41 2019

@author: pc
"""
import numpy as np

# Create sigmoid operation 

class sigmoid(Operation):
    """Returns the sigmoid of x element-wise """

    def __init__(self, a):
        """Construct sigmoid """
        super().__init__([a])

    def compute(self, a_value):
        """Compute the output of the sigmoid operation """
        return 1 / (1 + np.exp(-a_value))
    
# Create a new graph
Graph().as_default()

x = placeholder()
w = Variable([1, 1])
b = Variable(0)
p = sigmoid( add(matmul(w, x), b) )

# Using the perceptron

session = Session()
print(session.run(p, {x: [3, 2]}))


# Create softmax operation

class softmax(Operation):
    """ Returns softmax of a """
    
    def __init__(self, a):
        """ Construct softmax """
        
        super().__init__([a])
        
        def compute(self, a_value):
            """ Compute output of softmax operaton """
            
            return np.exp(a_value) / np.sum(np.exp(a_value), axis=1)[:, None]
        
# Create multiclass perceptron
            
Graph().as_default()

X = placeholder()

# Create weight matrix for 2 output classes:

W = Variable([
        [1, -1], 
        [1, -1]
        ])
b = Variable([0, 0])
p = softmax(add(matmul(X, w), b))


